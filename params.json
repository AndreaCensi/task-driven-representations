{"name":"Task-driven Representations","tagline":"","body":"# Task-driven Perceptual Representations: Sensing, Planning and Control under Resource Constraints\r\n\r\n## Proposed workshop for ICRA 2016\r\n\r\nOrganizers: [Andrea Censi (MIT)][censi],  [Stefano Soatto (UCLA)][soatto], [Panagiotis Tsiotras (GATech)][tsiotras]\r\n\r\nTechnical Committees endorsements:\r\n* RAS Technical Committee on Algorithms for Planning and Control of Robot Motion \r\n* RAS Technical Committee on Computer and Robot Vision\r\n\r\nDuration: full day\r\n\r\n## Description\r\n\r\nTextbook robotics relies on the duality of “inference” vs “control”, or “perception” vs “planning”. These are usually considered distinct problems that can be tackled separately, using the “belief” of the agent as the interface between the two. However, the two become entangled again when computational resources are constrained; this happens either in the regime where the available on-board computational resources are limited (small UAVs, robotic insects), as well as in the regime where environment and sensor data are complex.\r\n\r\nWhen computation, memory, or sensing bandwidth are constrained or are associated to a cost, many classical notions must be revised. The most efficient implementation of a behaviorally “optimal” agent does not estimate a belief over the state, but rather it estimates the “minimal representation”, which is the smallest statistic of the observations that is sufficient to perform the task, and is typically much smaller than the full belief. The best sensor is not the one that provides the most bits about the environment, but rather the one whose bits are most “informative” for the task at hand given available resources. If computation has a cost, the best agent aims to achieve “bounded rationality” or “rational inattention”.  \r\n\r\nThe goal of this workshop is to bring together the researchers in robotics who have been working from many complementary angles on the general issue of designing optimal agents under resources constraints. We would like to understand together which of the competing formalizations are expressive enough to model the resource constraints of a realistic robotic system; which lead to tractable design problems; and whether there is an intersection between the two sets. We also would like to attract researchers in the neighboring fields of computer vision/machine learning and control/identification theory who work on largely equivalent problems.\r\n\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}